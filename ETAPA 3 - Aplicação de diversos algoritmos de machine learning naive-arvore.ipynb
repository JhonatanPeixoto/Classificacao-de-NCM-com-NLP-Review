{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a436b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5c6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar dados\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#diretório onde estão os arquivos .XLS\n",
    "#dir = r'C:\\TCC JHONATAN\\trabalho-final\\dados\\planilhas291\\\\'\n",
    "\n",
    "#dataframe vazio\n",
    "colunas = ['Código NCM','Descrição']\n",
    "df_sintetico = pd.DataFrame(columns=colunas)\n",
    "\n",
    "#df_sintetico = pd.read_csv('.\\dados_tratados_ncm_e_descricao.csv', dtype={'Código NCM': str})\n",
    "df_sintetico = pd.read_excel('./normalizados_dados_tratados_ncm_e_descricao.xlsx', dtype={'Código NCM': str})\n",
    "\n",
    "#df_sintetico['posição'] = df_sintetico['Código NCM'].apply(lambda x: str(x)[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d33013",
   "metadata": {},
   "source": [
    "## pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53e267",
   "metadata": {},
   "source": [
    "## Aplicação de algoritmos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f5e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import cross_val_score\\nfrom sklearn.feature_extraction.text import TfidfTransformer\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import LinearSVC\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import precision_score, recall_score, f1_score\\nimport pandas as pd\\nimport time\\n\\n# Dividir os dados em características (X) e rótulos (y)\\nlabels = df_sintetico[\\'Código NCM\\']\\ntext = df_sintetico[\\'Descrição\\']\\n\\n# Pré-processamento dos dados\\ncount_vect = CountVectorizer()\\nX_counts = count_vect.fit_transform(text)\\ntf_transformer = TfidfTransformer().fit(X_counts)\\nX_transformed = tf_transformer.transform(X_counts)\\n\\n# Definir os algoritmos de classificação\\nclassifiers = {\\n    \\'MultinomialNB\\': MultinomialNB(),\\n    #\\'RandomForestClassifier\\': RandomForestClassifier(),\\n    #\\'LogisticRegression\\': LogisticRegression(),\\n    \\'LinearSVC\\': LinearSVC(),\\n    #\\'KNN\\': KNeighborsClassifier()\\n}\\n\\n# Inicializar as listas de resultados\\nresults = []\\n\\n# Executar a classificação e obter os relatórios\\nfor classifier_name, classifier in classifiers.items():\\n    start_time = time.time()\\n    scores = cross_val_score(classifier, X_transformed, labels, cv=10)\\n    end_time = time.time()\\n    processing_time = end_time - start_time\\n    \\n    classifier.fit(X_transformed, labels)  # Ajustar o classificador aos dados\\n    predicted_labels = classifier.predict(X_transformed)  # Prever os rótulos\\n    \\n    accuracy = scores.mean()\\n    precision = precision_score(labels, predicted_labels, average=\\'weighted\\', zero_division=1)\\n    recall = recall_score(labels, predicted_labels, average=\\'weighted\\', zero_division=1)\\n    f1 = f1_score(labels, predicted_labels, average=\\'weighted\\', zero_division=1)\\n    \\n    results.append({\\'Algorithm\\': classifier_name, \\'Accuracy\\': accuracy,\\n                    \\'Precision\\': precision, \\'Recall\\': recall, \\'F1-Score\\': f1})\\n    \\n    print(f\"Accuracy for {classifier_name}: {accuracy}\")\\n    print(f\"Precision for {classifier_name}: {precision}\")\\n    print(f\"Recall for {classifier_name}: {recall}\")\\n    print(f\"F1-Score for {classifier_name}: {f1}\")\\n    print(f\"Processing Time for {classifier_name}: {processing_time} seconds\")\\n    print(\"---------------------------------------------------\")\\n\\n# Criar o DataFrame com os resultados\\nresults_df = pd.DataFrame(results)\\n\\n# Exibir o DataFrame com os resultados\\nprint(results_df)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Dividir os dados em características (X) e rótulos (y)\n",
    "labels = df_sintetico['Código NCM']\n",
    "text = df_sintetico['Descrição']\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(text)\n",
    "tf_transformer = TfidfTransformer().fit(X_counts)\n",
    "X_transformed = tf_transformer.transform(X_counts)\n",
    "\n",
    "# Definir os algoritmos de classificação\n",
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    #'RandomForestClassifier': RandomForestClassifier(),\n",
    "    #'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    #'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Inicializar as listas de resultados\n",
    "results = []\n",
    "\n",
    "# Executar a classificação e obter os relatórios\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    scores = cross_val_score(classifier, X_transformed, labels, cv=10)\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    classifier.fit(X_transformed, labels)  # Ajustar o classificador aos dados\n",
    "    predicted_labels = classifier.predict(X_transformed)  # Prever os rótulos\n",
    "    \n",
    "    accuracy = scores.mean()\n",
    "    precision = precision_score(labels, predicted_labels, average='weighted', zero_division=1)\n",
    "    recall = recall_score(labels, predicted_labels, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(labels, predicted_labels, average='weighted', zero_division=1)\n",
    "    \n",
    "    results.append({'Algorithm': classifier_name, 'Accuracy': accuracy,\n",
    "                    'Precision': precision, 'Recall': recall, 'F1-Score': f1})\n",
    "    \n",
    "    print(f\"Accuracy for {classifier_name}: {accuracy}\")\n",
    "    print(f\"Precision for {classifier_name}: {precision}\")\n",
    "    print(f\"Recall for {classifier_name}: {recall}\")\n",
    "    print(f\"F1-Score for {classifier_name}: {f1}\")\n",
    "    print(f\"Processing Time for {classifier_name}: {processing_time} seconds\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "# Criar o DataFrame com os resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Exibir o DataFrame com os resultados\n",
    "print(results_df)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c108904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Criar o DataFrame com os resultados\\nresults_df = pd.DataFrame(results)\\n\\n# Definir as métricas a serem exibidas no gráfico de barras\\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\\n\\n# Definir a largura das barras\\nbar_width = 0.15\\n\\n# Calcular a posição das barras no eixo x\\nx = np.arange(len(results_df))\\n\\n# Plotar o gráfico de barras agrupadas\\nplt.figure(figsize=(10, 6))\\nfor i, metric in enumerate(metrics):\\n    plt.bar(x + i * bar_width, results_df[metric], width=bar_width, label=metric)\\n \\n# Configurar os rótulos do eixo x\\nplt.xlabel('Algorithms')\\nplt.ylabel('Score')\\nplt.title('Performance Metrics of Different Classification Algorithms')\\nplt.xticks(x + (len(metrics) - 1) * bar_width / 2, results_df['Algorithm'], rotation=45)\\nplt.legend()\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Criar o DataFrame com os resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Definir as métricas a serem exibidas no gráfico de barras\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "# Definir a largura das barras\n",
    "bar_width = 0.15\n",
    "\n",
    "# Calcular a posição das barras no eixo x\n",
    "x = np.arange(len(results_df))\n",
    "\n",
    "# Plotar o gráfico de barras agrupadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i * bar_width, results_df[metric], width=bar_width, label=metric)\n",
    " \n",
    "# Configurar os rótulos do eixo x\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Metrics of Different Classification Algorithms')\n",
    "plt.xticks(x + (len(metrics) - 1) * bar_width / 2, results_df['Algorithm'], rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f17d88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAAM\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SAAM\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SAAM\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SAAM\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5403/5403 [==============================] - 217s 40ms/step - loss: 1.9085 - accuracy: 0.5797 - val_loss: 0.9480 - val_accuracy: 0.7437\n",
      "Epoch 2/10\n",
      "5403/5403 [==============================] - 209s 39ms/step - loss: 0.9391 - accuracy: 0.7453 - val_loss: 0.6733 - val_accuracy: 0.8049\n",
      "Epoch 3/10\n",
      "5403/5403 [==============================] - 198s 37ms/step - loss: 0.7043 - accuracy: 0.7999 - val_loss: 0.4967 - val_accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "5403/5403 [==============================] - 199s 37ms/step - loss: 0.5564 - accuracy: 0.8354 - val_loss: 0.4004 - val_accuracy: 0.8772\n",
      "Epoch 5/10\n",
      "5403/5403 [==============================] - 221s 41ms/step - loss: 0.4568 - accuracy: 0.8622 - val_loss: 0.3217 - val_accuracy: 0.8986\n",
      "Epoch 6/10\n",
      "5403/5403 [==============================] - 230s 42ms/step - loss: 0.3878 - accuracy: 0.8786 - val_loss: 0.2822 - val_accuracy: 0.9098\n",
      "Epoch 7/10\n",
      "5403/5403 [==============================] - 229s 42ms/step - loss: 0.3401 - accuracy: 0.8924 - val_loss: 0.2387 - val_accuracy: 0.9226\n",
      "Epoch 8/10\n",
      "5403/5403 [==============================] - 230s 43ms/step - loss: 0.3028 - accuracy: 0.9034 - val_loss: 0.2203 - val_accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "5403/5403 [==============================] - 230s 43ms/step - loss: 0.2787 - accuracy: 0.9100 - val_loss: 0.2060 - val_accuracy: 0.9307\n",
      "Epoch 10/10\n",
      "5403/5403 [==============================] - 230s 43ms/step - loss: 0.2583 - accuracy: 0.9162 - val_loss: 0.1946 - val_accuracy: 0.9350\n",
      "5403/5403 [==============================] - 8s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>Algoritmo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Código NCM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02012010</th>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.480851</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02012020</th>\n",
       "      <td>0.779891</td>\n",
       "      <td>0.916933</td>\n",
       "      <td>0.842878</td>\n",
       "      <td>313.0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02012090</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02013000</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.572988</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02022010</th>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96151100</th>\n",
       "      <td>0.975659</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>500.0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96159000</th>\n",
       "      <td>0.942598</td>\n",
       "      <td>0.925816</td>\n",
       "      <td>0.934132</td>\n",
       "      <td>337.0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96162000</th>\n",
       "      <td>0.979675</td>\n",
       "      <td>0.952569</td>\n",
       "      <td>0.965932</td>\n",
       "      <td>253.0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96170010</th>\n",
       "      <td>0.980119</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>500.0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96190000</th>\n",
       "      <td>0.996016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>500.0</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            precision    recall  f1-score  support    Algoritmo\n",
       "Código NCM                                                     \n",
       "02012010     0.904000  0.480851  0.627778    235.0  Naive Bayes\n",
       "02012020     0.779891  0.916933  0.842878    313.0  Naive Bayes\n",
       "02012090     0.900000  0.540000  0.675000    200.0  Naive Bayes\n",
       "02013000     0.434783  0.840000  0.572988    500.0  Naive Bayes\n",
       "02022010     0.698745  0.698745  0.698745    239.0  Naive Bayes\n",
       "...               ...       ...       ...      ...          ...\n",
       "96151100     0.975659  0.962000  0.968781    500.0          CNN\n",
       "96159000     0.942598  0.925816  0.934132    337.0          CNN\n",
       "96162000     0.979675  0.952569  0.965932    253.0          CNN\n",
       "96170010     0.980119  0.986000  0.983051    500.0          CNN\n",
       "96190000     0.996016  1.000000  0.998004    500.0          CNN\n",
       "\n",
       "[2016 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Dividir os dados em características (X) e rótulos (y)\n",
    "labels = df_sintetico['Código NCM']\n",
    "text = df_sintetico['Descrição']\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_transformed = tfidf_vectorizer.fit_transform(text)\n",
    "\n",
    "# Treinar o classificador MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_transformed, labels)\n",
    "\n",
    "# Realizar a predição no conjunto de treinamento\n",
    "y_pred_nb = naive_bayes.predict(X_transformed)\n",
    "\n",
    "# Obter o classification_report para o Naive Bayes como um DataFrame\n",
    "report_nb = pd.DataFrame(classification_report(labels, y_pred_nb, output_dict=True)).transpose()\n",
    "report_nb['Algoritmo'] = 'Naive Bayes'\n",
    "report_nb.index.name = 'Código NCM'\n",
    "\n",
    "# Treinar o classificador Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_transformed, labels)\n",
    "\n",
    "# Realizar a predição no conjunto de treinamento\n",
    "y_pred_svc = linear_svc.predict(X_transformed)\n",
    "\n",
    "# Obter o classification_report para o Linear SVC como um DataFrame\n",
    "report_svc = pd.DataFrame(classification_report(labels, y_pred_svc, output_dict=True)).transpose()\n",
    "report_svc['Algoritmo'] = 'Linear SVC'\n",
    "report_svc.index.name = 'Código NCM'\n",
    "\n",
    "# Treinar o classificador Random Forest\n",
    "random_forest = RandomForestClassifier(max_depth=100)\n",
    "random_forest.fit(X_transformed, labels)\n",
    "\n",
    "# Realizar a predição no conjunto de treinamento\n",
    "y_pred_rf = random_forest.predict(X_transformed)\n",
    "\n",
    "# Obter o classification_report para o Random Forest como um DataFrame\n",
    "report_rf = pd.DataFrame(classification_report(labels, y_pred_rf, output_dict=True)).transpose()\n",
    "report_rf['Algoritmo'] = 'Random Forest'\n",
    "report_rf.index.name = 'Código NCM'\n",
    "\n",
    "##################\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X = df_sintetico['Descrição'].values\n",
    "y = df_sintetico['Código NCM'].values\n",
    "\n",
    "# Pré-processamento dos dados de texto\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "max_len = max(len(x) for x in X)\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "\n",
    "# Codificar as classes alvo\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "y_encoded = to_categorical(y_encoded)\n",
    "\n",
    "# Construção da arquitetura da CNN\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(X, y_encoded, epochs=10, batch_size=32, validation_data=(X, y_encoded))\n",
    "\n",
    "# Avaliar o modelo usando o conjunto de teste\n",
    "y_pred = model.predict(X)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_classes = np.argmax(y_encoded, axis=1)\n",
    "report_cnn = classification_report(y_classes, y_pred_classes, output_dict=True)\n",
    "report_cnn_df = pd.DataFrame(report_cnn).transpose()\n",
    "\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "report_cnn_df = report_cnn_df.drop(\"accuracy\")\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "report_cnn_df = report_cnn_df.drop(\"macro avg\")\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "report_cnn_df = report_cnn_df.drop(\"weighted avg\")\n",
    "\n",
    "# Reverter a codificação do índice\n",
    "report_cnn_df.index = label_encoder.inverse_transform(report_cnn_df.index.astype(int))\n",
    "\n",
    "report_cnn_df['Algoritmo'] = 'CNN'\n",
    "report_cnn_df.index.name = 'Código NCM'\n",
    "\n",
    "##################\n",
    "\n",
    "# Combinar os DataFrames dos algoritmos\n",
    "results_df = pd.concat([report_nb, report_svc, report_rf, report_cnn_df])\n",
    "\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "results_df = results_df.drop(\"accuracy\")\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "results_df = results_df.drop(\"macro avg\")\n",
    "# Excluir a entrada \"accuracy\" do classification_report\n",
    "results_df = results_df.drop(\"weighted avg\")\n",
    "\n",
    "# Exportar o DataFrame para um arquivo Excel\n",
    "results_df.to_excel('classification_report.xlsx')\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658bbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "\n",
    "def bip():\n",
    "    frequency = 1000  # Frequência do bip (em Hz)\n",
    "    duration = 200  # Duração do bip (em milissegundos)\n",
    "    winsound.Beep(frequency, duration)\n",
    "\n",
    "# Chamando a função para reproduzir o som de bip\n",
    "bip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6249684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
